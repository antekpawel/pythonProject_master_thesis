{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dalex as dx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "##\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "##\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "##\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "##\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_features(transformed_features, components_, columns):\n",
    "    \"\"\"\n",
    "    This function will return the most \"important\" \n",
    "    features so we can determine which have the most\n",
    "    effect on multi-dimensional scaling\n",
    "    \"\"\"\n",
    "    num_columns = len(columns)\n",
    "\n",
    "    # Scale the principal components by the max value in\n",
    "    # the transformed set belonging to that component\n",
    "    xvector = components_[0] * max(transformed_features[:,0])\n",
    "    yvector = components_[1] * max(transformed_features[:,1])\n",
    "\n",
    "    # Sort each column by it's length. These are your *original*\n",
    "    # columns, not the principal components.\n",
    "    important_features = { columns[i] : math.sqrt(xvector[i]**2 + yvector[i]**2) for i in range(num_columns) }\n",
    "    important_features = sorted(zip(important_features.values(), important_features.keys()), reverse=True)\n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "databank = pd.read_csv('data.csv',low_memory=False, index_col=0)\n",
    "databank.columns = databank.columns.str.lower()\n",
    "databank.columns = databank.columns.str.rsplit('(', n=1).str.get(0)\n",
    "databank.columns = databank.columns.str.replace(\" \", \"_\")\n",
    "databank.columns = databank.columns.str.replace(\"\\\\.\", \"\")\n",
    "databank.columns = databank.columns.str.replace(\"-\", \"_\")\n",
    "databank.columns = databank.columns.str.rstrip('_')\n",
    "##\n",
    "databank = databank.drop(['phase'], axis=1)\n",
    "databank['viscosity'] = pd.to_numeric(databank['viscosity'],errors = 'coerce')\n",
    "databank['therm_cond'] = pd.to_numeric(databank['therm_cond'],errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45432"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databank.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "databank = databank.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "databank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>density</th>\n",
       "      <th>internal_energy</th>\n",
       "      <th>enthalpy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cv</th>\n",
       "      <th>cp</th>\n",
       "      <th>sound_spd</th>\n",
       "      <th>joule_thomson</th>\n",
       "      <th>viscosity</th>\n",
       "      <th>therm_cond</th>\n",
       "      <th>fluid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.84</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>75.970</td>\n",
       "      <td>76.014</td>\n",
       "      <td>1402.4</td>\n",
       "      <td>-0.024141</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.56109</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.85</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.046483</td>\n",
       "      <td>75.963</td>\n",
       "      <td>76.004</td>\n",
       "      <td>1403.3</td>\n",
       "      <td>-0.024125</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.56141</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.86</td>\n",
       "      <td>0.025368</td>\n",
       "      <td>0.027170</td>\n",
       "      <td>0.092811</td>\n",
       "      <td>75.957</td>\n",
       "      <td>75.993</td>\n",
       "      <td>1404.1</td>\n",
       "      <td>-0.024109</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.56173</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.87</td>\n",
       "      <td>0.038033</td>\n",
       "      <td>0.039834</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>75.950</td>\n",
       "      <td>75.983</td>\n",
       "      <td>1404.9</td>\n",
       "      <td>-0.024092</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.56204</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.88</td>\n",
       "      <td>0.050696</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>0.185360</td>\n",
       "      <td>75.943</td>\n",
       "      <td>75.973</td>\n",
       "      <td>1405.8</td>\n",
       "      <td>-0.024076</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.56236</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  pressure  density  internal_energy  enthalpy   entropy  \\\n",
       "0       273.16       1.0   999.84         0.000033  0.001835  0.000121   \n",
       "1       273.33       1.0   999.85         0.012701  0.014503  0.046483   \n",
       "2       273.49       1.0   999.86         0.025368  0.027170  0.092811   \n",
       "3       273.66       1.0   999.87         0.038033  0.039834  0.139100   \n",
       "4       273.83       1.0   999.88         0.050696  0.052497  0.185360   \n",
       "\n",
       "       cv      cp  sound_spd  joule_thomson  viscosity  therm_cond   fluid  \n",
       "0  75.970  76.014     1402.4      -0.024141   0.001791     0.56109   Water  \n",
       "1  75.963  76.004     1403.3      -0.024125   0.001781     0.56141   Water  \n",
       "2  75.957  75.993     1404.1      -0.024109   0.001770     0.56173   Water  \n",
       "3  75.950  75.983     1404.9      -0.024092   0.001760     0.56204   Water  \n",
       "4  75.943  75.973     1405.8      -0.024076   0.001750     0.56236   Water  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = databank.drop(labels='fluid', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>density</th>\n",
       "      <th>internal_energy</th>\n",
       "      <th>enthalpy</th>\n",
       "      <th>entropy</th>\n",
       "      <th>cv</th>\n",
       "      <th>cp</th>\n",
       "      <th>sound_spd</th>\n",
       "      <th>joule_thomson</th>\n",
       "      <th>viscosity</th>\n",
       "      <th>therm_cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.284134</td>\n",
       "      <td>0.401420</td>\n",
       "      <td>0.458121</td>\n",
       "      <td>0.276476</td>\n",
       "      <td>-0.194763</td>\n",
       "      <td>-0.177681</td>\n",
       "      <td>-0.135023</td>\n",
       "      <td>0.032295</td>\n",
       "      <td>-0.297660</td>\n",
       "      <td>-0.228899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>-0.000070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072677</td>\n",
       "      <td>-0.054971</td>\n",
       "      <td>-0.059051</td>\n",
       "      <td>-0.136202</td>\n",
       "      <td>0.048334</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>0.052243</td>\n",
       "      <td>-0.097654</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>0.063586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>-0.284134</td>\n",
       "      <td>0.072677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.208803</td>\n",
       "      <td>-0.285342</td>\n",
       "      <td>-0.699045</td>\n",
       "      <td>0.913052</td>\n",
       "      <td>0.896221</td>\n",
       "      <td>0.967046</td>\n",
       "      <td>-0.223034</td>\n",
       "      <td>0.773671</td>\n",
       "      <td>0.988687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internal_energy</th>\n",
       "      <td>0.401420</td>\n",
       "      <td>-0.054971</td>\n",
       "      <td>-0.208803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995653</td>\n",
       "      <td>-0.032798</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>0.162262</td>\n",
       "      <td>-0.139770</td>\n",
       "      <td>0.827372</td>\n",
       "      <td>-0.232866</td>\n",
       "      <td>-0.199912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enthalpy</th>\n",
       "      <td>0.458121</td>\n",
       "      <td>-0.059051</td>\n",
       "      <td>-0.285342</td>\n",
       "      <td>0.995653</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031985</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.083138</td>\n",
       "      <td>-0.208780</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>-0.286944</td>\n",
       "      <td>-0.274136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.276476</td>\n",
       "      <td>-0.136202</td>\n",
       "      <td>-0.699045</td>\n",
       "      <td>-0.032798</td>\n",
       "      <td>0.031985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.656624</td>\n",
       "      <td>-0.654669</td>\n",
       "      <td>-0.707087</td>\n",
       "      <td>-0.042692</td>\n",
       "      <td>-0.562709</td>\n",
       "      <td>-0.692140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>-0.194763</td>\n",
       "      <td>0.048334</td>\n",
       "      <td>0.913052</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>-0.656624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.866492</td>\n",
       "      <td>0.056538</td>\n",
       "      <td>0.726820</td>\n",
       "      <td>0.895988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>-0.177681</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>0.896221</td>\n",
       "      <td>0.162262</td>\n",
       "      <td>0.083138</td>\n",
       "      <td>-0.654669</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846673</td>\n",
       "      <td>0.102654</td>\n",
       "      <td>0.656474</td>\n",
       "      <td>0.880594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound_spd</th>\n",
       "      <td>-0.135023</td>\n",
       "      <td>0.052243</td>\n",
       "      <td>0.967046</td>\n",
       "      <td>-0.139770</td>\n",
       "      <td>-0.208780</td>\n",
       "      <td>-0.707087</td>\n",
       "      <td>0.866492</td>\n",
       "      <td>0.846673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.223943</td>\n",
       "      <td>0.733957</td>\n",
       "      <td>0.980927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joule_thomson</th>\n",
       "      <td>0.032295</td>\n",
       "      <td>-0.097654</td>\n",
       "      <td>-0.223034</td>\n",
       "      <td>0.827372</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>-0.042692</td>\n",
       "      <td>0.056538</td>\n",
       "      <td>0.102654</td>\n",
       "      <td>-0.223943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.199242</td>\n",
       "      <td>-0.244067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viscosity</th>\n",
       "      <td>-0.297660</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>0.773671</td>\n",
       "      <td>-0.232866</td>\n",
       "      <td>-0.286944</td>\n",
       "      <td>-0.562709</td>\n",
       "      <td>0.726820</td>\n",
       "      <td>0.656474</td>\n",
       "      <td>0.733957</td>\n",
       "      <td>-0.199242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.718986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therm_cond</th>\n",
       "      <td>-0.228899</td>\n",
       "      <td>0.063586</td>\n",
       "      <td>0.988687</td>\n",
       "      <td>-0.199912</td>\n",
       "      <td>-0.274136</td>\n",
       "      <td>-0.692140</td>\n",
       "      <td>0.895988</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>0.980927</td>\n",
       "      <td>-0.244067</td>\n",
       "      <td>0.718986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 temperature  pressure   density  internal_energy  enthalpy  \\\n",
       "temperature         1.000000 -0.000070 -0.284134         0.401420  0.458121   \n",
       "pressure           -0.000070  1.000000  0.072677        -0.054971 -0.059051   \n",
       "density            -0.284134  0.072677  1.000000        -0.208803 -0.285342   \n",
       "internal_energy     0.401420 -0.054971 -0.208803         1.000000  0.995653   \n",
       "enthalpy            0.458121 -0.059051 -0.285342         0.995653  1.000000   \n",
       "entropy             0.276476 -0.136202 -0.699045        -0.032798  0.031985   \n",
       "cv                 -0.194763  0.048334  0.913052         0.112838  0.034962   \n",
       "cp                 -0.177681  0.074366  0.896221         0.162262  0.083138   \n",
       "sound_spd          -0.135023  0.052243  0.967046        -0.139770 -0.208780   \n",
       "joule_thomson       0.032295 -0.097654 -0.223034         0.827372  0.811404   \n",
       "viscosity          -0.297660  0.017558  0.773671        -0.232866 -0.286944   \n",
       "therm_cond         -0.228899  0.063586  0.988687        -0.199912 -0.274136   \n",
       "\n",
       "                  entropy        cv        cp  sound_spd  joule_thomson  \\\n",
       "temperature      0.276476 -0.194763 -0.177681  -0.135023       0.032295   \n",
       "pressure        -0.136202  0.048334  0.074366   0.052243      -0.097654   \n",
       "density         -0.699045  0.913052  0.896221   0.967046      -0.223034   \n",
       "internal_energy -0.032798  0.112838  0.162262  -0.139770       0.827372   \n",
       "enthalpy         0.031985  0.034962  0.083138  -0.208780       0.811404   \n",
       "entropy          1.000000 -0.656624 -0.654669  -0.707087      -0.042692   \n",
       "cv              -0.656624  1.000000  0.990040   0.866492       0.056538   \n",
       "cp              -0.654669  0.990040  1.000000   0.846673       0.102654   \n",
       "sound_spd       -0.707087  0.866492  0.846673   1.000000      -0.223943   \n",
       "joule_thomson   -0.042692  0.056538  0.102654  -0.223943       1.000000   \n",
       "viscosity       -0.562709  0.726820  0.656474   0.733957      -0.199242   \n",
       "therm_cond      -0.692140  0.895988  0.880594   0.980927      -0.244067   \n",
       "\n",
       "                 viscosity  therm_cond  \n",
       "temperature      -0.297660   -0.228899  \n",
       "pressure          0.017558    0.063586  \n",
       "density           0.773671    0.988687  \n",
       "internal_energy  -0.232866   -0.199912  \n",
       "enthalpy         -0.286944   -0.274136  \n",
       "entropy          -0.562709   -0.692140  \n",
       "cv                0.726820    0.895988  \n",
       "cp                0.656474    0.880594  \n",
       "sound_spd         0.733957    0.980927  \n",
       "joule_thomson    -0.199242   -0.244067  \n",
       "viscosity         1.000000    0.718986  \n",
       "therm_cond        0.718986    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = X.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature         True\n",
       "pressure            True\n",
       "density            False\n",
       "internal_energy    False\n",
       "enthalpy           False\n",
       "entropy             True\n",
       "cv                 False\n",
       "cp                 False\n",
       "sound_spd          False\n",
       "joule_thomson       True\n",
       "viscosity           True\n",
       "therm_cond         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_corr = ~(corr.mask(np.eye(len(corr), dtype=bool)).abs() > 0.95).any() # 0.95 / 0.99\n",
    "features_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_good = corr.loc[features_corr, features_corr]\n",
    "lst_variable_corr = X_good.columns.values.tolist()\n",
    "X_corr = X[np.intersect1d(X.columns, lst_variable_corr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>joule_thomson</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>viscosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.024141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.16</td>\n",
       "      <td>0.001791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046483</td>\n",
       "      <td>-0.024125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.33</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.092811</td>\n",
       "      <td>-0.024109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.49</td>\n",
       "      <td>0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139100</td>\n",
       "      <td>-0.024092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.66</td>\n",
       "      <td>0.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185360</td>\n",
       "      <td>-0.024076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.83</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157649</th>\n",
       "      <td>100.010000</td>\n",
       "      <td>0.410190</td>\n",
       "      <td>15.0</td>\n",
       "      <td>572.33</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157650</th>\n",
       "      <td>100.020000</td>\n",
       "      <td>0.409930</td>\n",
       "      <td>15.0</td>\n",
       "      <td>572.50</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157651</th>\n",
       "      <td>100.030000</td>\n",
       "      <td>0.409660</td>\n",
       "      <td>15.0</td>\n",
       "      <td>572.67</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157652</th>\n",
       "      <td>100.040000</td>\n",
       "      <td>0.409390</td>\n",
       "      <td>15.0</td>\n",
       "      <td>572.83</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157653</th>\n",
       "      <td>100.050000</td>\n",
       "      <td>0.409130</td>\n",
       "      <td>15.0</td>\n",
       "      <td>573.00</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           entropy  joule_thomson  pressure  temperature  viscosity\n",
       "0         0.000121      -0.024141       1.0       273.16   0.001791\n",
       "1         0.046483      -0.024125       1.0       273.33   0.001781\n",
       "2         0.092811      -0.024109       1.0       273.49   0.001770\n",
       "3         0.139100      -0.024092       1.0       273.66   0.001760\n",
       "4         0.185360      -0.024076       1.0       273.83   0.001750\n",
       "...            ...            ...       ...          ...        ...\n",
       "157649  100.010000       0.410190      15.0       572.33   0.000024\n",
       "157650  100.020000       0.409930      15.0       572.50   0.000024\n",
       "157651  100.030000       0.409660      15.0       572.67   0.000024\n",
       "157652  100.040000       0.409390      15.0       572.83   0.000024\n",
       "157653  100.050000       0.409130      15.0       573.00   0.000024\n",
       "\n",
       "[135250 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = X[X_corr.columns]\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    " - https://benalexkeen.com/principle-component-analysis-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=12, svd_solver='full')\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "components = pd.DataFrame(pca.components_, columns = X.columns, index=[1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca_result = get_important_features(T, pca.components_, X.columns.values)\n",
    "pca_result = pd.DataFrame(pca_result,columns=['PCA_Value','Variable'])\n",
    "threshold = 3\n",
    "pca_result = pca_result[pca_result[\"PCA_Value\"] >= 3]\n",
    "pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca_result['Variable']\n",
    "df_pca = X[X_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_enc = preprocessing.LabelEncoder()\n",
    "databank[\"fluid\"] = lb_enc.fit_transform(databank[\"fluid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = databank.fluid\n",
    "X = df_corr # df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify = databank['fluid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass as One-Vs-One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'rbf',\n",
      " 'max_iter': -1,\n",
      " 'nu': 0.5,\n",
      " 'probability': False,\n",
      " 'random_state': None,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "clf_nusvc = NuSVC()\n",
    "clf_nusvc.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_nusvc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'break_ties': [True, False],\n",
      " 'cache_size': [200, 500, 1000],\n",
      " 'class_weight': [None],\n",
      " 'coef0': [0],\n",
      " 'decision_function_shape': ['ovr'],\n",
      " 'degree': [3, 5, 7, 10],\n",
      " 'gamma': ['scale', 'auto'],\n",
      " 'max_iter': [-1],\n",
      " 'nu': [0.5],\n",
      " 'probability': [True, False],\n",
      " 'random_state': [None],\n",
      " 'shrinking': [True, False],\n",
      " 'tol': [0.001],\n",
      " 'verbose': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "nusvc_params = {\n",
    "    'break_ties': [True,False],\n",
    "    'cache_size': [200,500,1000],\n",
    "    'class_weight': [None],\n",
    "    'coef0': [0],\n",
    "    'decision_function_shape': ['ovr'],\n",
    "    'degree': [3,5,7,10],\n",
    "    'gamma': ['scale','auto'],\n",
    "    'max_iter': [-1],\n",
    "    'nu': [0.5],\n",
    "    'probability': [True,False],\n",
    "    'random_state': [None],\n",
    "    'shrinking': [True,False],\n",
    "    'tol': [0.001],\n",
    "    'verbose': [True,False]\n",
    "}\n",
    "pprint(nusvc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "random_nusvc = RandomizedSearchCV(estimator = clf_nusvc, \n",
    "                                  param_distributions = nusvc_params, \n",
    "                                  n_iter = 100, \n",
    "                                  cv = 5, \n",
    "                                  verbose=2, \n",
    "                                  random_state=42, \n",
    "                                  n_jobs = -1)\n",
    "random_nusvc.fit(X_train,y_train)\n",
    "random_nusvc.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_nusvc_clf = dx.Explainer(clf_nusvc, X_train, y_train)\n",
    "exp_nusvc_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_nusvc_random = dx.Explainer(random_nusvc, X_train, y_train)\n",
    "exp_nusvc_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_nusvc = exp_nusvc_clf.model_diagnostics()\n",
    "md_nusvc.plot(md_nusvc, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_nusvc = exp_nusvc_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_nusvc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'rbf',\n",
      " 'max_iter': -1,\n",
      " 'probability': False,\n",
      " 'random_state': None,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "clf_svc = SVC()\n",
    "clf_svc.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_svc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [1.0],\n",
      " 'break_ties': [True, False],\n",
      " 'cache_size': [200],\n",
      " 'class_weight': [None],\n",
      " 'coef0': [0.0],\n",
      " 'decision_function_shape': ['ovr'],\n",
      " 'degree': [3],\n",
      " 'gamma': ['scale', 'auto'],\n",
      " 'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
      " 'max_iter': [-1],\n",
      " 'probability': [True, False],\n",
      " 'random_state': [None],\n",
      " 'shrinking': [True, False],\n",
      " 'tol': [0.001],\n",
      " 'verbose': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "svc_params = {'C': [1.0],\n",
    "    'break_ties': [True,False],\n",
    "    'cache_size': [200],\n",
    "    'class_weight': [None],\n",
    "    'coef0': [0.0],\n",
    "    'decision_function_shape': ['ovr'],\n",
    "    'degree': [3],\n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel': ['linear','poly','rbf','sigmoid','precomputed'],\n",
    "    'max_iter': [-1],\n",
    "    'probability': [True,False],\n",
    "    'random_state': [None],\n",
    "    'shrinking': [True,False],\n",
    "    'tol': [0.001],\n",
    "    'verbose': [True,False]\n",
    "}\n",
    "pprint(svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "random_svc = RandomizedSearchCV(estimator = clf_svc, \n",
    "                                  param_distributions = svc_params, \n",
    "                                  n_iter = 100, \n",
    "                                  cv = 5, \n",
    "                                  verbose=2, \n",
    "                                  random_state=42, \n",
    "                                  n_jobs = -1)\n",
    "random_svc.fit(X_train,y_train)\n",
    "random_svc.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_svc_clf = dx.Explainer(clf_nusvc, X_train, y_train)\n",
    "exp_svc_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_svc_random = dx.Explainer(random_svc, X_train, y_train)\n",
    "exp_svc_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_svc = exp_svc_clf.model_diagnostics()\n",
    "md_svc.plot(md_nusvc, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_svc = exp_svc_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_svc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass as One-Vs-The-Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gbm = GradientBoostingClassifier()\n",
    "clf_gbm.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_gbm.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "}\n",
    "pprint(gbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_gbm = RandomizedSearchCV(estimator = clf_gbm, \n",
    "                                param_distributions = gbm_params, \n",
    "                                n_iter = 100, \n",
    "                                cv = 3, \n",
    "                                verbose=2, \n",
    "                                random_state=42, \n",
    "                                n_jobs = -1)\n",
    "random_gbm.fit(X_train,y_train)\n",
    "random_gbm.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gbm_clf = dx.Explainer(clf_gbm, X_train, y_train)\n",
    "exp_gbm_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_gbm_clf = dx.Explainer(random_gbm, X_train, y_train)\n",
    "exp_gbm_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_gbm = exp_gbm_clf.model_diagnostics()\n",
    "md_gbm.plot(md_gbm, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_gbm = exp_gbm_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_gbm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_linear = LinearSVC(multi_class=\"ovr\")\n",
    "clf_linear.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_linear.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_params = {\n",
    "    'C': [1.0],\n",
    "    'class_weight': ['dict','balanced'],\n",
    "    'dual': [True,False],\n",
    "    'fit_intercept': [True,False],\n",
    "    'intercept_scaling': [1],\n",
    "    'loss': ['hinge','squared_hinge'],\n",
    "    'max_iter': [500,1000,2500,5000,10000],\n",
    "    'multi_class': ['ovr'],\n",
    "    'penalty': ['l1','l2'],\n",
    "    'random_state': [0],\n",
    "    'tol': [0.0001],\n",
    "    'verbose': [0]\n",
    "}\n",
    "pprint(linear_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_linear = RandomizedSearchCV(estimator = clf_linear, \n",
    "                                  param_distributions = linear_params, \n",
    "                                  n_iter = 100, \n",
    "                                  cv = 5, \n",
    "                                  verbose=2, \n",
    "                                  random_state=42, \n",
    "                                  n_jobs = -1)\n",
    "random_linear.fit(X_train,y_train)\n",
    "random_linear.best_params_nie                                  `````````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_linear_clf = dx.Explainer(clf_linear, X_train, y_train)\n",
    "exp_linear_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_linear_random = dx.Explainer(random_linear, X_train, y_train)\n",
    "exp_linear_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_linear = exp_logit_clf.model_diagnostics()\n",
    "md_linear.plot(md_logit, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_linear = exp_linear_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_linear.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_logit = LogisticRegression(random_state=0, multi_class=\"ovr\")\n",
    "clf_logit.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_logit.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_params = {\n",
    "     'C': [1.0],\n",
    "     'class_weight': [None],\n",
    "     'dual': [False], \n",
    "     'fit_intercept': [True,False],\n",
    "     'intercept_scaling': [1],\n",
    "     'l1_ratio': [0.1,0.5,0.7],\n",
    "     'max_iter': [50,100,150,200,250], \n",
    "     'penalty': ['l2','elasticnet'],\n",
    "     'random_state': [0],\n",
    "     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "     'tol': [0.0001],\n",
    "     'verbose': [0],\n",
    "     'warm_start': [True,False],  \n",
    "     'n_jobs': [-1]\n",
    "}\n",
    "pprint(logit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_logit = RandomizedSearchCV(estimator = clf_logit, \n",
    "                                  param_distributions = logit_params, \n",
    "                                  n_iter = 100, \n",
    "                                  cv = 5, \n",
    "                                  verbose=2, \n",
    "                                  random_state=42, \n",
    "                                  n_jobs = -1)\n",
    "random_logit.fit(X_train,y_train)\n",
    "random_logit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_logit_clf = dx.Explainer(clf_logit, X_train, y_train)\n",
    "exp_logit_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_logit_random = dx.Explainer(random_logit, X_train, y_train)\n",
    "exp_logit_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_logit = exp_logit_clf.model_diagnostics()\n",
    "md_logit.plot(md_logit, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_logit = exp_logit_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_logit.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_logit_cv = LogisticRegressionCV(multi_class=\"ovr\")\n",
    "clf_logit_cv.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_logit_cv.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_cv_params = {'Cs': [5,10,15,20],\n",
    "    'class_weight': [None],\n",
    "    'cv': [3,5,10],\n",
    "    'dual': [True,False],\n",
    "    'fit_intercept': [True,False],\n",
    "    'intercept_scaling': [1.0],\n",
    "    'l1_ratios': ['l1','l2','elasticnet'],\n",
    "    'max_iter': [50,100,150,250],\n",
    "    'n_jobs': [-1],\n",
    "    'penalty': ['l1','l2','elasticnet'],\n",
    "    'random_state': [0],\n",
    "    'refit': [True,False],\n",
    "    'scoring': [None],\n",
    "    'solver': ['lbfgs'],\n",
    "    'tol': [0.0001],\n",
    "    'verbose': [0]}\n",
    "pprint(logit_cv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_logit_cv = RandomizedSearchCV(estimator = clf_logit_cv, \n",
    "                                param_distributions = logit_cv_params, \n",
    "                                n_iter = 100, \n",
    "                                cv = 5, \n",
    "                                verbose=2, \n",
    "                                random_state=42, \n",
    "                                n_jobs = -1)\n",
    "random_logit_cv.fit(X_train,y_train)\n",
    "random_logit_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_logit_cv_clf = dx.Explainer(clf_logit_cv, X_train, y_train)\n",
    "exp_logit_cv_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_logit_cv_random = dx.Explainer(random_logit_cv, X_train, y_train)\n",
    "exp_logit_cv_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_logit_cv_clf = exp_logit_cv_clf.model_diagnostics()\n",
    "md_logit_cv_clf.plot(md_logit_cv_clf, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_logit_cv_clf = exp_logit_cv_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_logit_cv_clf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sgd = SGDClassifier()\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_sgd.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "    'alpha': [0.0001],\n",
    "    'average': [True,False],\n",
    "    'class_weight': [None],\n",
    "    'early_stopping': [True,False],\n",
    "    'epsilon': [0.1],\n",
    "    'eta0': [0.1],\n",
    "    'fit_intercept': [True,False],\n",
    "    'l1_ratio': [0.1,0.2,0.3],\n",
    "    'learning_rate': ['constant','optimal','invscaling'],\n",
    "    'loss': ['hinge','log','modified_huber','squared_hinge','perceptron'],\n",
    "    'max_iter': [100,500,1000,10000],\n",
    "    'n_iter_no_change': [5],\n",
    "    'n_jobs': [-1],\n",
    "    'penalty': ['l2','l1','elasticnet'],\n",
    "    'power_t': [0.5,0.7,0.9],\n",
    "    'random_state': [None],\n",
    "    'shuffle': [True,False],\n",
    "    'tol': [0.001],\n",
    "    'validation_fraction': [0.1],\n",
    "    'verbose': [0],\n",
    "    'warm_start': [True,False]\n",
    "}\n",
    "pprint(sgd_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_sgd = RandomizedSearchCV(estimator = clf_sgd, \n",
    "                                param_distributions = sgd_params, \n",
    "                                n_iter = 100, \n",
    "                                cv = 5, \n",
    "                                verbose=2, \n",
    "                                random_state=42, \n",
    "                                n_jobs = -1)\n",
    "random_sgd.fit(X_train,y_train)\n",
    "random_sgd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_sgd_clf = dx.Explainer(clf_sgd, X_train, y_train)\n",
    "exp_sgd_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_sgd_random = dx.Explainer(random_sgd, X_train, y_train)\n",
    "exp_sgd_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_sgd = exp_sgd_random.model_diagnostics()\n",
    "md_sgd.plot(md_sgd, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lime_sgd = exp_sgd_random.predict_surrogate(X.iloc[[1]])\n",
    "lime_sgd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_perceptron = Perceptron()\n",
    "clf_perceptron.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_perceptron.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_params = {\n",
    "    'alpha': [0.0001],\n",
    "    'class_weight': ['balanced','weight','dict'],\n",
    "    'early_stopping': [True,False],\n",
    "    'eta0': [0.5,0.7,1],\n",
    "    'fit_intercept': [True,False],\n",
    "    'max_iter': [100,500,1000,10000],\n",
    "    'n_iter_no_change': [2,5,10],\n",
    "    'n_jobs': [-1],\n",
    "    'penalty': ['l2','l1','elasticnet'],\n",
    "    'random_state': [0],\n",
    "    'shuffle': [True,False],\n",
    "    'tol': [0.001],\n",
    "    'validation_fraction':[0.1],\n",
    "    'verbose': [0],\n",
    "    'warm_start': [True,False]\n",
    "}\n",
    "pprint(perceptron_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_perceptron = RandomizedSearchCV(estimator = clf_perceptron, \n",
    "                                       param_distributions = perceptron_params, \n",
    "                                       n_iter = 100, \n",
    "                                       cv = 5, \n",
    "                                       verbose=2, \n",
    "                                       random_state=42, \n",
    "                                       n_jobs = -1)\n",
    "random_perceptron.fit(X_train,y_train)\n",
    "random_perceptron.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_perceptron_clf = dx.Explainer(clf_perceptron, X_train, y_train)\n",
    "exp_perceptron_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_perceptron_random = dx.Explainer(random_perceptron, X_train, y_train)\n",
    "exp_perceptron_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_perceptron = exp_perceptron_clf.model_diagnostics()\n",
    "md_perceptron.plot(md_perceptron, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lime_perceptron = exp_perceptron_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_perceptron.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_passive_aggressive = PassiveAggressiveClassifier()\n",
    "clf_passive_aggressive.fit(X_train, y_train)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(clf_passive_aggressive.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_aggressive_params = {\n",
    "    'C': [0.5,0.7,1.0,2.0],\n",
    "    'average': [True,False],\n",
    "    'class_weight': ['dict','balanced',None],\n",
    "    'early_stopping': [True,False],\n",
    "    'fit_intercept': [True,False],\n",
    "    'loss': ['hinge','squared_hinge'],\n",
    "    'max_iter': [100,250,500,1000,10000],\n",
    "    'n_iter_no_change': [5,10,15,20],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [42],\n",
    "    'shuffle': [True,False],\n",
    "    'tol': [0.001],\n",
    "    'validation_fraction': [0.1,0.5,0.7],\n",
    "    'verbose': [0],\n",
    "    'warm_start': [True,False]\n",
    "}\n",
    "pprint(passive_aggressive_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_passive_aggressive = RandomizedSearchCV(estimator = clf_passive_aggressive, \n",
    "                                               param_distributions = passive_aggressive_params, \n",
    "                                               n_iter = 100, \n",
    "                                               cv = 5, \n",
    "                                               verbose=2, \n",
    "                                               random_state=42, \n",
    "                                               n_jobs = -1)\n",
    "random_passive_aggressive.fit(X_train,y_train)\n",
    "random_passive_aggressive.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_passive_aggressive_clf = dx.Explainer(clf_passive_aggressive, X_train, y_train)\n",
    "exp_passive_aggressive_clf.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_passive_aggressive_random = dx.Explainer(random_passive_aggressive, X_train, y_train)\n",
    "exp_passive_aggressive_random.model_performance().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_passive_aggressive = exp_passive_aggressive_clf.model_diagnostics()\n",
    "md_passive_aggressive.plot(md_passive_aggressive, variable='entropy', yvariable='residuals', marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lime_passive_aggressive = exp_passive_aggressive_clf.predict_surrogate(X.iloc[[1]])\n",
    "lime_passive_aggressive.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
